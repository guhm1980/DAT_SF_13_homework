{
 "metadata": {
  "name": "",
  "signature": "sha256:6cdf44fbb0bf351ac97d8d62a15015306c2953ce169c07af6815a61304a49882"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from __future__ import division\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from seaborn import plt\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.datasets import load_iris\n",
      "from sklearn import neighbors, datasets, feature_selection\n",
      "from sklearn.cross_validation import train_test_split, cross_val_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris = datasets.load_iris()\n",
      "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
      "iris_df.describe()\n",
      "iris_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>sepal length (cm)</th>\n",
        "      <th>sepal width (cm)</th>\n",
        "      <th>petal length (cm)</th>\n",
        "      <th>petal width (cm)</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 5.1</td>\n",
        "      <td> 3.5</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 4.9</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 4.7</td>\n",
        "      <td> 3.2</td>\n",
        "      <td> 1.3</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 4.6</td>\n",
        "      <td> 3.1</td>\n",
        "      <td> 1.5</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 5.0</td>\n",
        "      <td> 3.6</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
        "0                5.1               3.5                1.4               0.2\n",
        "1                4.9               3.0                1.4               0.2\n",
        "2                4.7               3.2                1.3               0.2\n",
        "3                4.6               3.1                1.5               0.2\n",
        "4                5.0               3.6                1.4               0.2"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_neighbors = range(1, 51, 2)\n",
      "print n_neighbors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = iris.target\n",
      "type(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "numpy.ndarray"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print iris"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'target_names': array(['setosa', 'versicolor', 'virginica'], \n",
        "      dtype='|S10'), 'data': array([[ 5.1,  3.5,  1.4,  0.2],\n",
        "       [ 4.9,  3. ,  1.4,  0.2],\n",
        "       [ 4.7,  3.2,  1.3,  0.2],\n",
        "       [ 4.6,  3.1,  1.5,  0.2],\n",
        "       [ 5. ,  3.6,  1.4,  0.2],\n",
        "       [ 5.4,  3.9,  1.7,  0.4],\n",
        "       [ 4.6,  3.4,  1.4,  0.3],\n",
        "       [ 5. ,  3.4,  1.5,  0.2],\n",
        "       [ 4.4,  2.9,  1.4,  0.2],\n",
        "       [ 4.9,  3.1,  1.5,  0.1],\n",
        "       [ 5.4,  3.7,  1.5,  0.2],\n",
        "       [ 4.8,  3.4,  1.6,  0.2],\n",
        "       [ 4.8,  3. ,  1.4,  0.1],\n",
        "       [ 4.3,  3. ,  1.1,  0.1],\n",
        "       [ 5.8,  4. ,  1.2,  0.2],\n",
        "       [ 5.7,  4.4,  1.5,  0.4],\n",
        "       [ 5.4,  3.9,  1.3,  0.4],\n",
        "       [ 5.1,  3.5,  1.4,  0.3],\n",
        "       [ 5.7,  3.8,  1.7,  0.3],\n",
        "       [ 5.1,  3.8,  1.5,  0.3],\n",
        "       [ 5.4,  3.4,  1.7,  0.2],\n",
        "       [ 5.1,  3.7,  1.5,  0.4],\n",
        "       [ 4.6,  3.6,  1. ,  0.2],\n",
        "       [ 5.1,  3.3,  1.7,  0.5],\n",
        "       [ 4.8,  3.4,  1.9,  0.2],\n",
        "       [ 5. ,  3. ,  1.6,  0.2],\n",
        "       [ 5. ,  3.4,  1.6,  0.4],\n",
        "       [ 5.2,  3.5,  1.5,  0.2],\n",
        "       [ 5.2,  3.4,  1.4,  0.2],\n",
        "       [ 4.7,  3.2,  1.6,  0.2],\n",
        "       [ 4.8,  3.1,  1.6,  0.2],\n",
        "       [ 5.4,  3.4,  1.5,  0.4],\n",
        "       [ 5.2,  4.1,  1.5,  0.1],\n",
        "       [ 5.5,  4.2,  1.4,  0.2],\n",
        "       [ 4.9,  3.1,  1.5,  0.1],\n",
        "       [ 5. ,  3.2,  1.2,  0.2],\n",
        "       [ 5.5,  3.5,  1.3,  0.2],\n",
        "       [ 4.9,  3.1,  1.5,  0.1],\n",
        "       [ 4.4,  3. ,  1.3,  0.2],\n",
        "       [ 5.1,  3.4,  1.5,  0.2],\n",
        "       [ 5. ,  3.5,  1.3,  0.3],\n",
        "       [ 4.5,  2.3,  1.3,  0.3],\n",
        "       [ 4.4,  3.2,  1.3,  0.2],\n",
        "       [ 5. ,  3.5,  1.6,  0.6],\n",
        "       [ 5.1,  3.8,  1.9,  0.4],\n",
        "       [ 4.8,  3. ,  1.4,  0.3],\n",
        "       [ 5.1,  3.8,  1.6,  0.2],\n",
        "       [ 4.6,  3.2,  1.4,  0.2],\n",
        "       [ 5.3,  3.7,  1.5,  0.2],\n",
        "       [ 5. ,  3.3,  1.4,  0.2],\n",
        "       [ 7. ,  3.2,  4.7,  1.4],\n",
        "       [ 6.4,  3.2,  4.5,  1.5],\n",
        "       [ 6.9,  3.1,  4.9,  1.5],\n",
        "       [ 5.5,  2.3,  4. ,  1.3],\n",
        "       [ 6.5,  2.8,  4.6,  1.5],\n",
        "       [ 5.7,  2.8,  4.5,  1.3],\n",
        "       [ 6.3,  3.3,  4.7,  1.6],\n",
        "       [ 4.9,  2.4,  3.3,  1. ],\n",
        "       [ 6.6,  2.9,  4.6,  1.3],\n",
        "       [ 5.2,  2.7,  3.9,  1.4],\n",
        "       [ 5. ,  2. ,  3.5,  1. ],\n",
        "       [ 5.9,  3. ,  4.2,  1.5],\n",
        "       [ 6. ,  2.2,  4. ,  1. ],\n",
        "       [ 6.1,  2.9,  4.7,  1.4],\n",
        "       [ 5.6,  2.9,  3.6,  1.3],\n",
        "       [ 6.7,  3.1,  4.4,  1.4],\n",
        "       [ 5.6,  3. ,  4.5,  1.5],\n",
        "       [ 5.8,  2.7,  4.1,  1. ],\n",
        "       [ 6.2,  2.2,  4.5,  1.5],\n",
        "       [ 5.6,  2.5,  3.9,  1.1],\n",
        "       [ 5.9,  3.2,  4.8,  1.8],\n",
        "       [ 6.1,  2.8,  4. ,  1.3],\n",
        "       [ 6.3,  2.5,  4.9,  1.5],\n",
        "       [ 6.1,  2.8,  4.7,  1.2],\n",
        "       [ 6.4,  2.9,  4.3,  1.3],\n",
        "       [ 6.6,  3. ,  4.4,  1.4],\n",
        "       [ 6.8,  2.8,  4.8,  1.4],\n",
        "       [ 6.7,  3. ,  5. ,  1.7],\n",
        "       [ 6. ,  2.9,  4.5,  1.5],\n",
        "       [ 5.7,  2.6,  3.5,  1. ],\n",
        "       [ 5.5,  2.4,  3.8,  1.1],\n",
        "       [ 5.5,  2.4,  3.7,  1. ],\n",
        "       [ 5.8,  2.7,  3.9,  1.2],\n",
        "       [ 6. ,  2.7,  5.1,  1.6],\n",
        "       [ 5.4,  3. ,  4.5,  1.5],\n",
        "       [ 6. ,  3.4,  4.5,  1.6],\n",
        "       [ 6.7,  3.1,  4.7,  1.5],\n",
        "       [ 6.3,  2.3,  4.4,  1.3],\n",
        "       [ 5.6,  3. ,  4.1,  1.3],\n",
        "       [ 5.5,  2.5,  4. ,  1.3],\n",
        "       [ 5.5,  2.6,  4.4,  1.2],\n",
        "       [ 6.1,  3. ,  4.6,  1.4],\n",
        "       [ 5.8,  2.6,  4. ,  1.2],\n",
        "       [ 5. ,  2.3,  3.3,  1. ],\n",
        "       [ 5.6,  2.7,  4.2,  1.3],\n",
        "       [ 5.7,  3. ,  4.2,  1.2],\n",
        "       [ 5.7,  2.9,  4.2,  1.3],\n",
        "       [ 6.2,  2.9,  4.3,  1.3],\n",
        "       [ 5.1,  2.5,  3. ,  1.1],\n",
        "       [ 5.7,  2.8,  4.1,  1.3],\n",
        "       [ 6.3,  3.3,  6. ,  2.5],\n",
        "       [ 5.8,  2.7,  5.1,  1.9],\n",
        "       [ 7.1,  3. ,  5.9,  2.1],\n",
        "       [ 6.3,  2.9,  5.6,  1.8],\n",
        "       [ 6.5,  3. ,  5.8,  2.2],\n",
        "       [ 7.6,  3. ,  6.6,  2.1],\n",
        "       [ 4.9,  2.5,  4.5,  1.7],\n",
        "       [ 7.3,  2.9,  6.3,  1.8],\n",
        "       [ 6.7,  2.5,  5.8,  1.8],\n",
        "       [ 7.2,  3.6,  6.1,  2.5],\n",
        "       [ 6.5,  3.2,  5.1,  2. ],\n",
        "       [ 6.4,  2.7,  5.3,  1.9],\n",
        "       [ 6.8,  3. ,  5.5,  2.1],\n",
        "       [ 5.7,  2.5,  5. ,  2. ],\n",
        "       [ 5.8,  2.8,  5.1,  2.4],\n",
        "       [ 6.4,  3.2,  5.3,  2.3],\n",
        "       [ 6.5,  3. ,  5.5,  1.8],\n",
        "       [ 7.7,  3.8,  6.7,  2.2],\n",
        "       [ 7.7,  2.6,  6.9,  2.3],\n",
        "       [ 6. ,  2.2,  5. ,  1.5],\n",
        "       [ 6.9,  3.2,  5.7,  2.3],\n",
        "       [ 5.6,  2.8,  4.9,  2. ],\n",
        "       [ 7.7,  2.8,  6.7,  2. ],\n",
        "       [ 6.3,  2.7,  4.9,  1.8],\n",
        "       [ 6.7,  3.3,  5.7,  2.1],\n",
        "       [ 7.2,  3.2,  6. ,  1.8],\n",
        "       [ 6.2,  2.8,  4.8,  1.8],\n",
        "       [ 6.1,  3. ,  4.9,  1.8],\n",
        "       [ 6.4,  2.8,  5.6,  2.1],\n",
        "       [ 7.2,  3. ,  5.8,  1.6],\n",
        "       [ 7.4,  2.8,  6.1,  1.9],\n",
        "       [ 7.9,  3.8,  6.4,  2. ],\n",
        "       [ 6.4,  2.8,  5.6,  2.2],\n",
        "       [ 6.3,  2.8,  5.1,  1.5],\n",
        "       [ 6.1,  2.6,  5.6,  1.4],\n",
        "       [ 7.7,  3. ,  6.1,  2.3],\n",
        "       [ 6.3,  3.4,  5.6,  2.4],\n",
        "       [ 6.4,  3.1,  5.5,  1.8],\n",
        "       [ 6. ,  3. ,  4.8,  1.8],\n",
        "       [ 6.9,  3.1,  5.4,  2.1],\n",
        "       [ 6.7,  3.1,  5.6,  2.4],\n",
        "       [ 6.9,  3.1,  5.1,  2.3],\n",
        "       [ 5.8,  2.7,  5.1,  1.9],\n",
        "       [ 6.8,  3.2,  5.9,  2.3],\n",
        "       [ 6.7,  3.3,  5.7,  2.5],\n",
        "       [ 6.7,  3. ,  5.2,  2.3],\n",
        "       [ 6.3,  2.5,  5. ,  1.9],\n",
        "       [ 6.5,  3. ,  5.2,  2. ],\n",
        "       [ 6.2,  3.4,  5.4,  2.3],\n",
        "       [ 5.9,  3. ,  5.1,  1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
        "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
        "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'DESCR': 'Iris Plants Database\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']}\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Questiion 1 - Implement KNN classification, using the sklearn package. \n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Loop through each neighbors value from 1 to 51 and append the scores\n",
      "scores = []\n",
      "for n in n_neighbors:\n",
      "    clf = neighbors.KNeighborsClassifier(n)\n",
      "    clf.fit(X_train, y_train)\n",
      "    scores.append(clf.score(X_test, y_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(n_neighbors, scores, linewidth=3.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "[<matplotlib.lines.Line2D at 0x10b032c50>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAECCAYAAAD9z2x7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIgAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10a00bcd0>"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1.0, 0.96666666666666667, 0.96666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.93333333333333335, 0.96666666666666667, 0.93333333333333335, 0.93333333333333335, 0.93333333333333335, 0.93333333333333335, 0.93333333333333335, 0.93333333333333335, 0.93333333333333335, 0.93333333333333335, 0.90000000000000002, 0.90000000000000002]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#On this trianing split, the ideal value for neighbors k is 9-27.   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Question 2 - implement cross validation \n",
      "\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "iris = datasets.load_iris()\n",
      "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
      "clf = neighbors.KNeighborsClassifier(9, weights='uniform')\n",
      "scores = cross_val_score(clf, iris_df.values, iris.target, cv=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print scores\n",
      "print scores.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.96666667  1.          0.96666667  0.93333333  1.        ]\n",
        "0.973333333333\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#we will try this on multiple values of K, based on the optimal range for k of 9-17 determined in Question #1\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "iris = datasets.load_iris()\n",
      "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
      "clf = neighbors.KNeighborsClassifier(11, weights='uniform')\n",
      "scores = cross_val_score(clf, iris_df.values, iris.target, cv=5)\n",
      "print scores\n",
      "print scores.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.93333333  1.          1.          0.96666667  1.        ]\n",
        "0.98\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "iris = datasets.load_iris()\n",
      "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
      "clf = neighbors.KNeighborsClassifier(17, weights='uniform')\n",
      "scores = cross_val_score(clf, iris_df.values, iris.target, cv=5)\n",
      "print scores\n",
      "print scores.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.93333333  1.          0.93333333  0.96666667  1.        ]\n",
        "0.966666666667\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Question 3 - determine optimal value for k \n",
      "# 5 fold generalization error is lowest when k = 11, and we see a fairly consistent representation of accuracy across all folds. "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Question 4 - Using matplotlib, plot classifier accuracy versus the hyperparameter K for a range of K that you consider interesting. Explain in words what you are seeing.\n",
      "\n",
      "scores = []\n",
      "for n in n_neighbors:\n",
      "    clf = neighbors.KNeighborsClassifier(n)\n",
      "    clf.fit(X_train, y_train)\n",
      "    scores.append(clf.score(X_test, y_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(n_neighbors, scores, linewidth=3.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "[<matplotlib.lines.Line2D at 0x10b167a90>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAECCAYAAAD9z2x7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3W1sZNd93/HvPJMccri75HAfSEZWFOnUVqxEzqLeaG3Z\nlqo0cSJITftGMJparVxHKQpDDWTLTuwCla3aFWQhQSw7luPKBRwb2EhqGwOWVSSC7GwqFZViSU6s\ns3p0yX0kuVw+D8l56Is7HN47S3I4M3c4c+f+PoDgmblzycPr5Y9nzjn3fyKlUgkREel+0XY3QERE\n9oYCX0QkJBT4IiIhocAXEQkJBb6ISEgo8EVEQiK+mzcZY94LfNFa+6Gq128FPgvkgW9aa79hjIkC\njwDXAavAXdbaN/xttoiI1KtmD98Y80ngUSBV9XoC+DJwC/AB4N8aY0aA24GUtfYG4D7gIb8bLSIi\n9dvNkM7rwG8DkarX3wm8bq2ds9auA38D3AgcB74PYK19HjjqX3NFRKRRNQPfWvsEzpBNtQww53q+\nAAyWX593vV4oD/OIiEgbNRPEc8CA6/kAcAkn7N2vR621xSa+j4iI+GBXk7bbeBW42hizH1jCGc55\nECgBtwInjDHHgJdrfaFSqVSKRLwjRv/x0f/Ni69eAOBTv3OU9/3SaBNN9d9dX/hfnL+43O5myB5I\n98T57hd+s93NENlK9VD7juoJ/BKAMeYOoN9a+6gx5j8AP8D5pPBn1tqzxpgngVuMMSfL591Zs8WR\nCFNTC57XDg72VB7//evTmCOZOpraWiur+UrYx6IRvvjxXyUareu6b2toKM3MzJIvXyvo2n0tPvnV\nv6VQLLGUy3Pm7CUS8Vjb2pLNDlz2OxJWuhabstmB2m9y2VXgW2vfBm4oP/6O6/XvAd+rem8JuLuu\nVmxhbKS/8njywmKzX85Xp6c2Q+jwUB9Drj9OzRoa7KW4ttWUSfi0+1r09yWYW1wDYH5pnaHB9gW+\niB86djJ1POsK/KnOCvwJV3vcf5ikuwz2JSuP55fX2tgSEX90bOAfGuojVh4mmZ7LsZzrnF6v+xOH\n+w+TdJdMejPw55YU+BJ8HRv48ViUw0PpyvPT053Ty1cPPxzcgT+vwJcu0LGBDzA+shn4nTKOXyqV\nPG0ZUw+/aynwpdt0dOC7e88TU52xcmVmLkdurQBAf2+Cff3JGmdIUGX6FPjSXTo68D0Ttx3Sw/cM\n52TTVN8/IN1jMK1JW+kuHR34nqWZU4sUO2DDdc9wjsbvu5qGdKTbdHTgD6aT9PcmAMitFZiZy7W5\nRd6hJa3Q6W6DWqUjXaajAz8SiTDeYTdgeZZkHlTgdzP18KXbdHTgg3cVzESbA391vcD5WaekQiQC\nR1zLRqX79Pcm2JiiWcrlyRdUA1CCreMDf9yzUqe9gX9meomNaYRDB/pIJnSrfTeLRiMMuFbqLCyv\nt7E1Is0LVOC3e0hnQuvvQ0dLM6WbdHzgHxnuq3ysvjC7wmp5DXw7aIVO+AymE5XHmriVoOv4wE/E\nYxw60Ac49ZlPT7fvBix3ETet0AkHTdxKN+n4wIeqYZ02jeOXSiXvkM6IJmzDIKObr6SLBCLwO2Gl\nzqXFNZbKFTt7UzGGMv7VwJfOpR6+dJNgBH4HTNxWT9iqpEI4aNJWukkgAr96M5RSG0osTKokcijp\nblvpJoEI/AOZFL0pZzfGpVye2YXVPW+DNj0JJ43hSzcJROBHIhHGs67a+G2YuNWmJ+GkMXzpJoEI\nfKiqjb/H4/jr+SLnZpYrz0eHtUInLAb6EmzM1iwur1MoqryCBJcCfxfOzixRKDrzBiP7eivDS9L9\nYtEo6XLF1hIqryDBFpjA907c7u3NVxO6wzbUBjWsI10iMIE/mk1XPlqfm1lmPb93JRYmq3a5knDR\nOL50i8AEfk8yTnZ/LwDFUokz08s1zvCPZ4WOevihk9HSTOkSgQl8uHw9/l5x73KlIZ3w8dx8paWZ\nEmCBCvx2TNzOLa1VPsYnE1Gy+3r35PtK58i4KmZqSEeCLFiB34Yevnf8vp+oSiqEjsbwpVsEKvDH\nXRUq96qmzqQ2PQk9rdKRbhGowB/e10uqvK3g/PL6nkygacJWvJO2WocvwRWowI9GIp5lkXvRy5/Q\nkszQ06StdItABT7s7cRtoVjkzLRW6ISdu4e/sLxGsbj31VpF/BC8wN/DidtzF1fIF5xf7gOZFOme\nRI0zpBvFY1HSPU45jVIJFlc0rCPBFLjAH9/DHv7EhYXKY03YhptW6kg3CFzgu8fRz0wvkS+0rnrh\n5IXN4RxN2Iabexx/TuP4ElCBC/y+ngRDmRQAhWKJcxdbV2LBPWSkwA839fClGwQu8AHGRwYqj1u5\nUqd6H1sJLwW+dIMdC7sbY6LAI8B1wCpwl7X2DdfxO4B7gRxwwlr7cPmcbwDXAEXgY9Za62ejx0bS\n/Pj1acBZNnnMzy9etriyXtlKMR6LcvCASiqEmW6+km5Qq4d/O5C01t4A3Ac8tHHAGDMEPADcBBwH\nbjPGXA/8GpC21r4P+E/AF/xutGelzoXW1MY/7RrOGR1OE4sG8sOQ+EQ9fOkGtVLsOPAUgLX2eeCo\n69hVwEvW2kvW2hLwHHAjsAIMGmMiwCDg+2+Hezy9VUszvZue6IarsPPcbatJWwmoWnv1ZYB51/OC\nMSZqrS0CrwHXGmNGgEXgZuAJ4G+AHuBVYAi41e9Gj+zvJRGPsp4vMruwyuLKOv29/q6R90zYavw+\n9DSkI92gVuDPAwOu5xthj7V21hhzD/A4MAO8WP7fTwEnrbV/YIwZA/7aGPOL1todf0uy2YGdDl/m\nikMDvD45B8DiWpErf66+82s5N7tSefyLV4/U3b5m7OX36nSdci1K8Vjl8eJKvi3t6pRr0Ql0LRpT\nK/BP4vTQTxhjjgEvbxwwxsSBo9ba9xtjUsCzwH8B/jWbnwpmgQQQo4apqYVab/E4tL+vEvivvHaB\nQ4Opus7fSbFY4u2zmx9s+lPRutvXqGx2YM++V6frpGuRd22pObe4yvkL83taKruTrkW76VpsqvcP\nX60x/CeBnDHmJM6E7T3GmDuMMR+z1uZxhnheAH4EfL28gudB4Jgx5kfAXwGfttaubPcNGuWua+P3\n0sypSyusrTs3dA2mk56bbiScEvEYvSmnf1QolljO5dvcIpH67djDL0/G3l318inX8fuB+6vOuQT8\nM78auJ1xd9VMnyduvRO2Gr8XRyadZGXVCfq5xVXf541EWi2waw1HXUF8emrJ1wqG7sDXhK1sGOzT\nVocSbIEN/ExfksF+Z6hlLV/k/Kx/JRY82xpqSaaUaWmmBF1gAx+8ve/JKf9uwFJJBdmK9+YrlUiW\n4Al04LdiM5SV1TzTczkAYtEIR4bVwxeH7raVoAt04I+3YKXOadcnhcNDfcRjgb5E4iMFvgRdoNNs\nvAW7X3n2sNUKHXEZ1N62EnCBDvxDQ33Eos7NL9NzOV/WRk9qhY5swzNpqx6+BFCgAz8ei3J4aHOM\n/fR087189fBlOxrSkaALdOADjLuWTTY7jl8qlTxfQyt0xM0d+AvLa5RK/t37IbIXAh/4npU6TS7N\nnJnLkVtzaqb09ybY16+SCrIplYiRSjplofKFEsurKq8gwRL4wPdM3DbZw/cM52TTRPawOJYEg2fi\nVsM6EjCBD/yxqs1Qik18zJ5UDR2pQeP4EmSBD/zBdLJSxCq3VqjcNNUI1dCRWrRSR4Is8IEfiUR8\nuwHLPQegHr5sRT18CbLABz5Ub2reWOCvrhe4cNEpwBaJoJIKsqWMu2Kmbr6SgOmOwHctzZxo8I7b\nM9NLbIz+H9zfRypRc5MuCSHtbStB1hWB78eQjmf8XsM5sg1VzJQg64rAHx1Os7GC8sLsCqtrhZ1P\n2IJW6MhuaNJWgqwrAj8Rj3HoQB8AJeD0dP03YLmLr2mFjmxHk7YSZF0R+FA1rFPnOH6pVKrax1YT\ntrK1TFXFTJVXkCDpmsB3r9SpdzOUS4trLJUrbfamYgxlenxtm3SPnmSMZNz5tVnPFyulOESCoHsC\nv4mJ2+otDVVSQbYTiUQ0rCOB1TWBX70ZSj0ftSdVElnqMKiJWwmorgn8A5kUvak4AEu5PLMLq7s+\nV5ueSD3Uw5egire7AX6JRCKMZ9OcmpwD4MkfvsnQ4O7G4u3Epcpj9fClllYszfzp2xeZXVzlH7/z\noPZRlpbpmsAHJ6w3Av/kT8419DVGVVJBasj4XCL5rbPzPPjdHwMwt7jGbxy7oumvKbKVrupKvPvn\nh5o6/5qxwcqwkMh2PEM6PtTT+cmbM5XHr7gei/itq9LtuquG+Pf//N387NxC3ef2peK8910HW9Aq\n6TZ+19NxV2mduOAsONBKMWmFrgr8SCTC9Vdnuf7qbLubIl3M70lb96KBpVyeS4tr7B9INf11Rap1\n1ZCOyF7wc9J2db3A+dllz2v13jgoslsKfJE6VZdXaMaZ6SWqbxmptzSIyG4p8EXq1JuKVZZOrq0X\nya3lG/5aW90V3syubSI7UeCL1CkSiTCYdu181cSwzlYb9jS6iY9ILQp8kQb4tRHKVr35czPLrOeL\nDX9Nke0o8EUa4B7Hb3TitlQqMelakplKOttqFoolzs7Uv6eDSC0KfJEG+HHz1aXFNRZXnE8HPckY\n77pif+WYVupIK+y4Dt8YEwUeAa4DVoG7rLVvuI7fAdwL5IAT1tqHy69/GrgVSAB/Yq39VmuaL9Ie\nfqzFn6jaVnN8pJ+/e20a0EodaY1aPfzbgaS19gbgPuChjQPGmCHgAeAm4DhwmzHmemPMB4FfLZ/z\nQeDnW9BukbbyI/Crt9V0b+KjlTrSCrUC/zjwFIC19nngqOvYVcBL1tpL1toS8BxwI/BrwCvGmP8O\n/CXwP31vtUib+VFeYXKLHv4Gd7kFEb/UCvwMMO96XigP8wC8BlxrjBkxxvQBNwNpYBjnD8O/AH4X\n+La/TRZpP8+kbYNj+BNVPfzsvl6SCefXa35pTZuriO9qBf48MOB+v7W2CGCtnQXuAR4H/hx4EZgG\nZoAfWGvz1tpTQM4YM+x7y0XaqNkhnfV8kXMzmyUVRrNpotEIo8PendtE/FSreNpJnMnXE8aYY8DL\nGweMMXHgqLX2/caYFPAs8CXgncAngC8bY47g9Ppr1nzNZgdqvSU0dC02deq16ElvFjdbWF6vu51v\nnZmjUHRqKhw80MfPjTkrdK65Yj9vnXU+VF+q+rqdei3aQdeiMbUC/0ngFmPMyfLzO8src/qttY8a\nYwrGmBeAAvA1a+2bwJvGmBuNMf8H5xPE75XH+Hc0NVV/SeNulM0O6FqUdfK1KJVKxKIRCsUSK6t5\nTp+5RDIR2/X5L9vzlcdHhvoqP+ewq0rmq2/OMFUu2d3J12Kv6VpsqvcP346BXw7qu6tePuU6fj9w\n/xbnfaquVogETCQSIZNOVvZOnl9aY3hf767Pn7ywOSnrnqwdy27uuKYSC+I33Xgl0qBmJm7dYe5e\njuneU/nM9BKFokosiH8U+CIN8kzcLtYX+O4lme4efronwYGMM6yTL5Q8E7sizVLgizQo46qYWU8P\n373kMpmIkq0aCnL3+DWsI35S4Is0qNGlme7llqPD/USj3v1r3T1+91i/SLMU+CINGuxrMPA9wznp\ny457Siyohy8+UuCLNKjRHr6naJor3CuvuUssqKaO+EiBL9KgRuvpeEoqjFwe+IcO9BKPOcM8swur\nlRLKIs1S4Is0yN3Dn1veXSgXikXOTG+Oy49u0cOPRaMcGd4c6jmtYR3xiQJfpEGNDOmcu7hCvuDc\neL5/IEV/b2LL941rWEdaQIEv0qB0b4JoxBl6WVnNs54v1Dxnu/X31cY1cSstoMAXaVA0EmHAtRZ/\nN5uZT25zh20178StlmaKPxT4Ik3wLM3cxc1X3m0NL1+SuXlsM/BPTy9WKmuKNEOBL9IEz8TtLsbx\nPdsajmxf6TDTl6ysAlpbL3J+Rr18aZ4CX6QJ9UzcLuXWuTjvVNeMxyIcOrBzdU13L/+tM/M7vFNk\ndxT4Ik2oJ/DdE7ZHhtPEojv/+rknbt86O9dgC0U2KfBFmpCpo7zCpGtj8vEdJmw3uMf431YPX3yg\nwBdpgudu2xqTtt4J210EvuuPwttnFfjSPAW+SBPqGtKZqi/wDw+liZUraZ6/uMzKar7BVoo4FPgi\nTdjtKp1iqeRdobOLIZ1EPMqhob7K89NTWqkjzVHgizRhtz38qdkV1taLlXPc5+3EU2JBd9xKkxT4\nIk0Y6E1Qrq7AUi5PvrD1HrTu8fvx7PY3XFXzlFhQTR1pkgJfpAnRaIQBVwG0hW2qZtY7fr/Ve9XD\nl2Yp8EWatJthnVqbnmxnrKqHXyqpxII0ToEv0qTdTNxO1tj0ZDv7+pOVEsq5tQIzc7kGWymiwBdp\nmjfwVy87vrKaZ+qSE9SxaITDQ7sfw49EIoy5xvxVG1+aocAXaVKtu21Pu3a4OjTURyJe36+dxvHF\nLwp8kSZ597a9fNLWs+lJHeP3W52jlTrSDAW+SJMyNcorTDS4QmercyZ085U0QYEv0qRaq3QmG1yh\ns+HIcJpyhQUuXFxmdb32VooiW1HgizRppzH8UnVJhQZ6+KlEjMPDznkl4My0evnSGAW+SJN2WpY5\nM59jZdXpkad74uzr311JhWpXHslUHmuljjRKgS/SpIG+zTttl1bWKRQ3yytMujYgHx/pJ7JRh6FO\n73AFviZupVEKfJEmxWPRys1RJbzlFSYuLFQeNzJ+v+HKw4OVx5NamikNUuCL+GC7iVv3qppGVuhs\neMdh75COSixIIxT4Ij7IuIZ13IHvWYPfROBn9/fSm4oBTlXOS4s7b7YishUFvogPtpq4XV0vcH52\nGYAIzvLKRjklFlzr8V1DRSK7pcAX8cFgOlV5vHHz1ZnpJTZGXkYO9JFKxJr6Hp4bsDRxKw2I73TQ\nGBMFHgGuA1aBu6y1b7iO3wHcC+SAE9bah13HRoAXgJuttada0HaRjpFJXz6kM9ngpifb8ZRY0B23\n0oBaPfzbgaS19gbgPuChjQPGmCHgAeAm4DhwmzHm+vKxBPCngP5VSihsNWk70eQNV9XcPXwtzZRG\n1Ar848BTANba54GjrmNXAS9Zay9Za0vAc8CN5WMPAl8FzvrbXJHONLhF4HtKKvgQ+KOuOYCzM8us\n57feTlFkO7UCPwPMu54XysM8AK8B1xpjRowxfcDNQNoY81Fgylr7dPl9jd1pIhIg3knb9XJJBddN\nV02swd/Qm4qT3dcDQLFU4uyMPkBLfWoF/jww4H6/tbYIYK2dBe4BHgf+HHgRmAbuBG4xxjwD/DLw\nLWPMQb8bLtJJPPV0lte4tLjG4opzA1ZPMsbQYI8v32d8ZPPXURO3Uq8dJ22Bk8CtwAljzDHg5Y0D\nxpg4cNRa+35jTAp4FviStfbrrvc8A3zcWnu+VkOy2YFabwkNXYtNQbkW+/ZvDrcsLq8xl8tXnl95\nZJCRkcxWp9Ulmx3AvOMAL56aAmBmcS0w18dvYf25m1Ur8J/E6a2fLD+/s7wyp99a+6gxpmCMeQEo\nAF+z1r7ZaEOmprSuGJx/yLoWjqBdi3RPnKVcnmIJnn/lTOX1Q/t7m/45Nq7FAddqoNd+djFQ18cv\nQft30Ur1/uHbMfDLk7F3V718ynX8fuD+Hc7/UF2tEQmwTDrJUrln//dvzVZe92PCdquvpc1QpF66\n8UrEJ+5xfE8NfB8mbDdk9/WSTDi/tvNLa5eVYxbZiQJfxCfulTpuoz7cdLUhWlViQZUzpR4KfBGf\nbBX4w4M99KZqTZXVx1NT57wCX3ZPgS/ik60C3487bHf6murhSz0U+CI+Gdwi8JvZ9GQ7Y64hIpVY\nkHoo8EV84p603dCKHr57pc6ZmSXyBZVYkN1R4Iv4ZK+GdNI9CQ5knHLM+UKJ8xeXff8e0p0U+CI+\ncZdIBkgmomT39bbke7mXek5oHF92SYEv4pPqMfzR4X6i0dbUDvSWStYNWLI7/q4XEwmxRDxGbyrG\nymoBgPER/9bfV3MPFb19bp7ZhdWWfa9OE03G2/7z9qXipJLN7WDWDgp8ER9l+pKsrK4ArVmhs8H9\ntf/h7Vl+/ysnd3i3+C0Rj3Lnh/8Rx951qN1NqYuGdER85B6zf8eh5itkbufggV56AtjD7Bbr+SJP\nPff/2t2MuqmHL+Kj2953JUu5PL8wOshVo60L/Fg0ykduuYbv/e3b5NYLLfs+nSgWjVAoltr2/ecW\ny5vUl5fExmPB6Tcr8EV8dNXoIJ/9V0drv9EHx999mOPvPrwn36uTtLs88r2PnGRmfpV8ocS5i8st\nHbrzW3D+NImIdABP8bqA3emswBcRqYN3TwIFvohI1xoP8D0QCnwRkToEuVqpAl9EpA4j+3tJxJ3o\nnF1YZXFlvc0t2j0FvohIHWLRKEeGg1miWoEvIlKnoBavU+CLiNTJW7xOgS8i0rXG3buOqYcvItK9\nRl09/NNTSxTbWOqhHgp8EZE6ZfqSDPY7+x+s5Yucnw3GrmMKfBGRBrgnbiengnEDlgJfRKQBnhIL\nAZm4VeCLiDRgPIBF1BT4IiINGAtgiQUFvohIAw4P9RErb1I/PZdjOZdvc4tqU+CLiDQgHotyeGhz\nPf7p6c7v5SvwRUQaND4SrJo6CnwRkQZ5N0Pp/KWZCnwRkQYFbaWOAl9EpEHVK3WKpc4usaDAFxFp\n0GA6SX9vAoDcWoHpuVybW7QzBb6ISIMikUjVHredPawT3+mgMSYKPAJcB6wCd1lr33AdvwO4F8gB\nJ6y1DxtjEsA3gSuAFPB5a+1ftqj9IiJtNZbt56c/mwWcwH/PNdk2t2h7tXr4twNJa+0NwH3AQxsH\njDFDwAPATcBx4DZjzPXAR4Apa+2NwK8Df9KKhouIdIIx19LMTt/9qlbgHweeArDWPg8cdR27CnjJ\nWnvJWlsCngNuBE4An3N9/c6//UxEpEFdM6QDZIB51/OCMSZqrS0CrwHXGmNGgEXgZuAJa+0SgDFm\nACf8/8D/ZouIdIbR4TSRCJRKcGF2hdW1AqlkrN3N2lKtwJ8HBlzPN8Iea+2sMeYe4HFgBngRmAYw\nxowDTwBfsdZ+dzcNyWYHar8pJHQtNulabNK12NRp12JspJ+J84uUgOVCibEOa9+GWoF/ErgVOGGM\nOQa8vHHAGBMHjlpr32+MSQHPAl8yxhwEngZ+z1r7zG4bMjW1UHfju1E2O6BrUaZrsUnXYlMnXovD\nB/qYOO8M57xy6gL7e2tFqz/q/cNXawz/SSBnjDmJM2F7jzHmDmPMx6y1eZwhnheAHwFft9a+CXwG\nGAQ+Z4x5pvxfT90/iYhIQIxlg7EZyo5/hsqTsXdXvXzKdfx+4P6qcz4BfMKvBoqIdLqxgEzc6sYr\nEZEmefe3XaTUoSUWFPgiIk06kEnRm3IGTJZyeWYXVtvcoq0p8EVEmhSJRBjPum7A6tBhHQW+iIgP\ngrDHrQJfRMQHns1Q1MMXEele3onbztz9SoEvIuKD0WyaSPnxuZll1vOFtrZnKwp8EREf9CTjZPf3\nAlAslTgzvdzmFl1OgS8i4pPq9fidRoEvIuKTTp+4VeCLiPhkTD18EZFwGHftftWJNXUU+CIiPhne\n10sq4Wx+Mr+8ztzSWptb5KXAFxHxSTQSYSzbub18Bb6IiI86eeJWgS8i4qNO3gxFgS8i4qPxDi6i\npsAXEfGRewz/zPQS+UKxja3xUuCLiPioryfBUMbZxrtQLHHuYueUWFDgi4j4bLxD97hV4IuI+GzM\ndQPWRAeN4yvwRUR85imxcKFzauMr8EVEfNapK3UU+CIiPhvZ30si7sTr7MIqiyvrbW6RQ4EvIuKz\nWDTKkeHOK7GgwBcRaYHxDrzjVoEvItICnpo6HTKOr8AXEWmB8Q6smqnAFxFpgVFXD//09BLFYqmN\nrXEo8EVEWiDTl2SwPwnAer7I+dn2l1hQ4IuItIh3PX77b8BS4IuItEinrdRR4IuItMhYhxVRU+CL\niLSIu4ffCSUWFPgiIi1yaKiPWDQCwPRcjuVcvq3tUeCLiLRIPBbl8NDmevzT0+3t5cd3OmiMiQKP\nANcBq8Bd1to3XMfvAO4FcsAJa+3Dtc4REQmT8ZF0ZThn8sIiV4/ta1tbavXwbweS1tobgPuAhzYO\nGGOGgAeAm4DjwG3GmOvL56S2OkdEJGw8JRbaPHFbK/CPA08BWGufB466jl0FvGStvWStLQHPATeW\nz/n+NueIiISKZ2lmmydudxzSATLAvOt5wRgTtdYWgdeAa40xI8AicDPwZI1zRERCxd3D/9m5Rf7o\nxEt1nT9+sJ8PH7uCnmStuK6t1leYBwZczyvBba2dNcbcAzwOzAAvAtPA0HbniIiEzWA6SX9vgsWV\ndfKFIi+9MVPX+S+9McO+/hQ3vWes6bbUCvyTwK3ACWPMMeDljQPGmDhw1Fr7fmNMCngW+BJO6G95\nzg4i2exA7XeFhK7FJl2LTboWm4J2Lb7z+Q+3uwkAREql7Su4GWMibK64AbgT+BWg31r7qDHmsziT\ntAXga9bab251jrX2VKt+ABER2Z0dA19ERLqHbrwSEQkJBb6ISEgo8EVEQkKBLyISEs2v5G+C6u6A\nMea9wBettR8yxvwC8BhQBH4C/LvyXcxdzxiTAL4JXAGkgM8DPyWE18MYEwMeBa4BSsDv4vx+PEbI\nrsWG8g2eL+Dc4FkkpNfCGPMiMFd++ibwn6njWrS7h79trZ4wMMZ8EucXO1V+6cvAZ6y1NwIR4LZ2\nta0NPgJMlX/2Xwe+gvPvIYzX47eAorX2fcAf4tSsCuu12OgM/CmwhPOzh/L3xBjTA2Ct/VD5v39D\nndei3YG/U62eMHgd+G2c/6MA3mOt/WH58feBf9KWVrXHCeBz5cdRYJ2QXg9r7f8APl5++g5gFviV\nMF6LsgeBrwJny89D+e8C+CWgzxjzA2PMX5VvbK3rWrQ78Lesu9Ouxuw1a+0TgHtHhIjr8SIwuLct\nah9r7ZK1dtEYM4AT/n+I999n2K5HwRjzGPBHwLcJ6b8NY8xHcT75PV1+KUJIrwXOJ5wHrbX/FGeY\n79tVx2vNslpRAAABQklEQVRei3aH67a1ekLK/bMPAJfa1ZB2MMaMA38N/Ddr7XcI+fWw1n4UMMA3\ngB7XoTBdizuBW4wxzwC/DHwLyLqOh+lanKIc8tba13BqmB10Ha95Ldod+CeBDwPUUXenm/2dMeYD\n5ce/Afxwpzd3E2PMQeBp4JPW2sfKL4fyehhj/qUx5tPlpys4pUv+bxivhbX2A9baD1prPwT8GPgd\n4KkwXgucP34PARhjjuAE/NP1XIu2rtLBKad8izHmZPn5ne1sTBttzKr/PvCoMSYJ/APwF+1r0p77\nDM7H0c8ZYzbG8j8B/HEIr8dfAI8ZY54FEjjX4VXC+2/DrUR4f0/+DPivxpiNUL8Tp5e/62uhWjoi\nIiHR7iEdERHZIwp8EZGQUOCLiISEAl9EJCQU+CIiIaHAFxEJCQW+iEhIKPBFRELi/wMA2uQyhPKp\nIgAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10a786ed0>"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# the ideal value for neighbors k is 9-27, at this value model accuracy is 100% "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Question 5 - Write your own implementation of cross validation "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris = datasets.load_iris()\n",
      "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
      "iris_df.describe()\n",
      "iris_df['target'] = iris.target  #append Target data to iris_df dataframe\n",
      "print iris_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
        "0                  5.1               3.5                1.4               0.2   \n",
        "1                  4.9               3.0                1.4               0.2   \n",
        "2                  4.7               3.2                1.3               0.2   \n",
        "3                  4.6               3.1                1.5               0.2   \n",
        "4                  5.0               3.6                1.4               0.2   \n",
        "5                  5.4               3.9                1.7               0.4   \n",
        "6                  4.6               3.4                1.4               0.3   \n",
        "7                  5.0               3.4                1.5               0.2   \n",
        "8                  4.4               2.9                1.4               0.2   \n",
        "9                  4.9               3.1                1.5               0.1   \n",
        "10                 5.4               3.7                1.5               0.2   \n",
        "11                 4.8               3.4                1.6               0.2   \n",
        "12                 4.8               3.0                1.4               0.1   \n",
        "13                 4.3               3.0                1.1               0.1   \n",
        "14                 5.8               4.0                1.2               0.2   \n",
        "15                 5.7               4.4                1.5               0.4   \n",
        "16                 5.4               3.9                1.3               0.4   \n",
        "17                 5.1               3.5                1.4               0.3   \n",
        "18                 5.7               3.8                1.7               0.3   \n",
        "19                 5.1               3.8                1.5               0.3   \n",
        "20                 5.4               3.4                1.7               0.2   \n",
        "21                 5.1               3.7                1.5               0.4   \n",
        "22                 4.6               3.6                1.0               0.2   \n",
        "23                 5.1               3.3                1.7               0.5   \n",
        "24                 4.8               3.4                1.9               0.2   \n",
        "25                 5.0               3.0                1.6               0.2   \n",
        "26                 5.0               3.4                1.6               0.4   \n",
        "27                 5.2               3.5                1.5               0.2   \n",
        "28                 5.2               3.4                1.4               0.2   \n",
        "29                 4.7               3.2                1.6               0.2   \n",
        "..                 ...               ...                ...               ...   \n",
        "120                6.9               3.2                5.7               2.3   \n",
        "121                5.6               2.8                4.9               2.0   \n",
        "122                7.7               2.8                6.7               2.0   \n",
        "123                6.3               2.7                4.9               1.8   \n",
        "124                6.7               3.3                5.7               2.1   \n",
        "125                7.2               3.2                6.0               1.8   \n",
        "126                6.2               2.8                4.8               1.8   \n",
        "127                6.1               3.0                4.9               1.8   \n",
        "128                6.4               2.8                5.6               2.1   \n",
        "129                7.2               3.0                5.8               1.6   \n",
        "130                7.4               2.8                6.1               1.9   \n",
        "131                7.9               3.8                6.4               2.0   \n",
        "132                6.4               2.8                5.6               2.2   \n",
        "133                6.3               2.8                5.1               1.5   \n",
        "134                6.1               2.6                5.6               1.4   \n",
        "135                7.7               3.0                6.1               2.3   \n",
        "136                6.3               3.4                5.6               2.4   \n",
        "137                6.4               3.1                5.5               1.8   \n",
        "138                6.0               3.0                4.8               1.8   \n",
        "139                6.9               3.1                5.4               2.1   \n",
        "140                6.7               3.1                5.6               2.4   \n",
        "141                6.9               3.1                5.1               2.3   \n",
        "142                5.8               2.7                5.1               1.9   \n",
        "143                6.8               3.2                5.9               2.3   \n",
        "144                6.7               3.3                5.7               2.5   \n",
        "145                6.7               3.0                5.2               2.3   \n",
        "146                6.3               2.5                5.0               1.9   \n",
        "147                6.5               3.0                5.2               2.0   \n",
        "148                6.2               3.4                5.4               2.3   \n",
        "149                5.9               3.0                5.1               1.8   \n",
        "\n",
        "     target  \n",
        "0         0  \n",
        "1         0  \n",
        "2         0  \n",
        "3         0  \n",
        "4         0  \n",
        "5         0  \n",
        "6         0  \n",
        "7         0  \n",
        "8         0  \n",
        "9         0  \n",
        "10        0  \n",
        "11        0  \n",
        "12        0  \n",
        "13        0  \n",
        "14        0  \n",
        "15        0  \n",
        "16        0  \n",
        "17        0  \n",
        "18        0  \n",
        "19        0  \n",
        "20        0  \n",
        "21        0  \n",
        "22        0  \n",
        "23        0  \n",
        "24        0  \n",
        "25        0  \n",
        "26        0  \n",
        "27        0  \n",
        "28        0  \n",
        "29        0  \n",
        "..      ...  \n",
        "120       2  \n",
        "121       2  \n",
        "122       2  \n",
        "123       2  \n",
        "124       2  \n",
        "125       2  \n",
        "126       2  \n",
        "127       2  \n",
        "128       2  \n",
        "129       2  \n",
        "130       2  \n",
        "131       2  \n",
        "132       2  \n",
        "133       2  \n",
        "134       2  \n",
        "135       2  \n",
        "136       2  \n",
        "137       2  \n",
        "138       2  \n",
        "139       2  \n",
        "140       2  \n",
        "141       2  \n",
        "142       2  \n",
        "143       2  \n",
        "144       2  \n",
        "145       2  \n",
        "146       2  \n",
        "147       2  \n",
        "148       2  \n",
        "149       2  \n",
        "\n",
        "[150 rows x 5 columns]\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#since the data is ordered, randomly shuffle\n",
      "iris_random = iris_df.reindex(np.random.permutation(iris_df.index))  \n",
      "print iris_random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
        "84                 5.4               3.0                4.5               1.5   \n",
        "49                 5.0               3.3                1.4               0.2   \n",
        "12                 4.8               3.0                1.4               0.1   \n",
        "28                 5.2               3.4                1.4               0.2   \n",
        "36                 5.5               3.5                1.3               0.2   \n",
        "123                6.3               2.7                4.9               1.8   \n",
        "131                7.9               3.8                6.4               2.0   \n",
        "100                6.3               3.3                6.0               2.5   \n",
        "7                  5.0               3.4                1.5               0.2   \n",
        "130                7.4               2.8                6.1               1.9   \n",
        "31                 5.4               3.4                1.5               0.4   \n",
        "74                 6.4               2.9                4.3               1.3   \n",
        "16                 5.4               3.9                1.3               0.4   \n",
        "114                5.8               2.8                5.1               2.4   \n",
        "29                 4.7               3.2                1.6               0.2   \n",
        "96                 5.7               2.9                4.2               1.3   \n",
        "85                 6.0               3.4                4.5               1.6   \n",
        "22                 4.6               3.6                1.0               0.2   \n",
        "90                 5.5               2.6                4.4               1.2   \n",
        "62                 6.0               2.2                4.0               1.0   \n",
        "42                 4.4               3.2                1.3               0.2   \n",
        "83                 6.0               2.7                5.1               1.6   \n",
        "97                 6.2               2.9                4.3               1.3   \n",
        "112                6.8               3.0                5.5               2.1   \n",
        "45                 4.8               3.0                1.4               0.3   \n",
        "11                 4.8               3.4                1.6               0.2   \n",
        "48                 5.3               3.7                1.5               0.2   \n",
        "21                 5.1               3.7                1.5               0.4   \n",
        "105                7.6               3.0                6.6               2.1   \n",
        "18                 5.7               3.8                1.7               0.3   \n",
        "..                 ...               ...                ...               ...   \n",
        "32                 5.2               4.1                1.5               0.1   \n",
        "6                  4.6               3.4                1.4               0.3   \n",
        "102                7.1               3.0                5.9               2.1   \n",
        "110                6.5               3.2                5.1               2.0   \n",
        "104                6.5               3.0                5.8               2.2   \n",
        "8                  4.4               2.9                1.4               0.2   \n",
        "67                 5.8               2.7                4.1               1.0   \n",
        "107                7.3               2.9                6.3               1.8   \n",
        "147                6.5               3.0                5.2               2.0   \n",
        "140                6.7               3.1                5.6               2.4   \n",
        "101                5.8               2.7                5.1               1.9   \n",
        "122                7.7               2.8                6.7               2.0   \n",
        "64                 5.6               2.9                3.6               1.3   \n",
        "68                 6.2               2.2                4.5               1.5   \n",
        "59                 5.2               2.7                3.9               1.4   \n",
        "79                 5.7               2.6                3.5               1.0   \n",
        "121                5.6               2.8                4.9               2.0   \n",
        "15                 5.7               4.4                1.5               0.4   \n",
        "23                 5.1               3.3                1.7               0.5   \n",
        "129                7.2               3.0                5.8               1.6   \n",
        "58                 6.6               2.9                4.6               1.3   \n",
        "40                 5.0               3.5                1.3               0.3   \n",
        "78                 6.0               2.9                4.5               1.5   \n",
        "69                 5.6               2.5                3.9               1.1   \n",
        "144                6.7               3.3                5.7               2.5   \n",
        "95                 5.7               3.0                4.2               1.2   \n",
        "98                 5.1               2.5                3.0               1.1   \n",
        "117                7.7               3.8                6.7               2.2   \n",
        "13                 4.3               3.0                1.1               0.1   \n",
        "141                6.9               3.1                5.1               2.3   \n",
        "\n",
        "     target  \n",
        "84        1  \n",
        "49        0  \n",
        "12        0  \n",
        "28        0  \n",
        "36        0  \n",
        "123       2  \n",
        "131       2  \n",
        "100       2  \n",
        "7         0  \n",
        "130       2  \n",
        "31        0  \n",
        "74        1  \n",
        "16        0  \n",
        "114       2  \n",
        "29        0  \n",
        "96        1  \n",
        "85        1  \n",
        "22        0  \n",
        "90        1  \n",
        "62        1  \n",
        "42        0  \n",
        "83        1  \n",
        "97        1  \n",
        "112       2  \n",
        "45        0  \n",
        "11        0  \n",
        "48        0  \n",
        "21        0  \n",
        "105       2  \n",
        "18        0  \n",
        "..      ...  \n",
        "32        0  \n",
        "6         0  \n",
        "102       2  \n",
        "110       2  \n",
        "104       2  \n",
        "8         0  \n",
        "67        1  \n",
        "107       2  \n",
        "147       2  \n",
        "140       2  \n",
        "101       2  \n",
        "122       2  \n",
        "64        1  \n",
        "68        1  \n",
        "59        1  \n",
        "79        1  \n",
        "121       2  \n",
        "15        0  \n",
        "23        0  \n",
        "129       2  \n",
        "58        1  \n",
        "40        0  \n",
        "78        1  \n",
        "69        1  \n",
        "144       2  \n",
        "95        1  \n",
        "98        1  \n",
        "117       2  \n",
        "13        0  \n",
        "141       2  \n",
        "\n",
        "[150 rows x 5 columns]\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#run model on one fold of the 150 sample, using array slicing \n",
      "firstFit = neighbors.KNeighborsClassifier(11)\n",
      "trainX = np.array(iris_random.ix[:,:4].values)[:120]\n",
      "trainY = np.array(iris_random.ix[:,4].values)[:120]\n",
      "firstFit.fit(trainX, trainY)\n",
      "testX = np.array(iris_random.ix[:,:4].values)[120:150]\n",
      "testY = np.array(iris_random.ix[:,4].values)[120:150]\n",
      "scoreOne = firstFit.score(testX, testY)\n",
      "print scoreOne         \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "secondFit = neighbors.KNeighborsClassifier(11)\n",
      "trainX2 = np.array(iris_random.ix[:,:4].values)[30:150]\n",
      "trainY2 = np.array(iris_random.ix[:,4].values)[30:150]\n",
      "firstFit.fit(trainX2, trainY2)\n",
      "testX2 = np.array(iris_random.ix[:,:4].values)[:30]\n",
      "testY2 = np.array(iris_random.ix[:,4].values)[:30]\n",
      "scoreTwo = firstFit.score(testX2, testY2)\n",
      "print scoreTwo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.966666666667\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ThirdFit = neighbors.KNeighborsClassifier(11)\n",
      "trainX3 = np.concatenate((np.array(iris_random.ix[:,:4].values)[:90], np.array(iris_random.ix[:,:4].values)[120:150]))\n",
      "trainY3 = np.concatenate((np.array(iris_random.ix[:,4].values)[:90], np.array(iris_random.ix[:,4].values)[120:150]))\n",
      "ThirdFit.fit(trainX3, trainY3)\n",
      "testX3 = np.array(iris_random.ix[:,:4].values)[90:120]\n",
      "testY3 = np.array(iris_random.ix[:,4].values)[90:120]\n",
      "scoreThree = ThirdFit.score(testX3, testY3)\n",
      "print scoreThree"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.933333333333\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FourthFit = neighbors.KNeighborsClassifier(11)\n",
      "trainX4 = np.concatenate((np.array(iris_random.ix[:,:4].values)[:30], np.array(iris_random.ix[:,:4].values)[60:150]))\n",
      "trainY4 = np.concatenate((np.array(iris_random.ix[:,4].values)[:30], np.array(iris_random.ix[:,4].values)[60:150]))\n",
      "FourthFit.fit(trainX4, trainY4)\n",
      "testX4 = np.array(iris_random.ix[:,:4].values)[30:60]\n",
      "testY4 = np.array(iris_random.ix[:,4].values)[30:60]\n",
      "scoreFour = FourthFit.score(testX4, testY4)\n",
      "print scoreFour"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.933333333333\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FifthFit = neighbors.KNeighborsClassifier(11)\n",
      "trainX5 = np.concatenate((np.array(iris_random.ix[:,:4].values)[:60], np.array(iris_random.ix[:,:4].values)[90:150]))\n",
      "trainY5 = np.concatenate((np.array(iris_random.ix[:,4].values)[:60], np.array(iris_random.ix[:,4].values)[90:150]))\n",
      "FifthFit.fit(trainX5, trainY5)\n",
      "testX5 = np.array(iris_random.ix[:,:4].values)[60:90]\n",
      "testY5 = np.array(iris_random.ix[:,4].values)[60:90]\n",
      "scoreFive = FifthFit.score(testX5, testY5)\n",
      "print scoreFive"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.933333333333\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FinalScore = (scoreOne + scoreTwo + scoreThree + scoreFour + scoreFive)/5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print FinalScore"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.953333333333\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#6 - Extra - play with different values for k folds, and determine whether there's an optimal \n",
      "from sklearn.cross_validation import cross_val_score\n",
      "iris = datasets.load_iris()\n",
      "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
      "clf = neighbors.KNeighborsClassifier(11, weights='uniform')\n",
      "scores = cross_val_score(clf, iris_df.values, iris.target, cv=10)\n",
      "print scores\n",
      "print scores.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 1.          0.93333333  1.          1.          1.          0.86666667\n",
        "  0.93333333  0.93333333  1.          1.        ]\n",
        "0.966666666667\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#  The error rate of the model goes up when # of folds gets below 4 and above 8, this is likely because we are undertraining \n",
      "# when k gets too high and the training set for each fold becomes too low; or we are overfitting if k is too small"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}